{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Running on GPUs",
   "id": "99edeca8c4a39634"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "There are differnt options to run your code on GPUs. The most common ones are:\n",
    "\n",
    "- **Google Colab**: A free cloud service that provides Jupyter notebooks with GPU support. You can use it to run your code on a GPU without any setup.\n",
    "- **Local GPU**: If you have a GPU on your local machine, you can run your code on it using PyTorch or TensorFlow. You need to install the appropriate drivers and libraries to use the GPU.\n",
    "- **Cloud GPU**: You can rent a GPU from a cloud provider like AWS, Google Cloud, or Azure. This option is more expensive but allows you to use powerful GPUs for your projects."
   ],
   "id": "42f3c057101a2f19"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T15:51:20.975385Z",
     "start_time": "2025-04-18T15:51:20.972897Z"
    }
   },
   "cell_type": "code",
   "source": "import torch",
   "id": "b534d29265182d2f",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T15:51:22.022200Z",
     "start_time": "2025-04-18T15:51:22.019092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")"
   ],
   "id": "d69c040c03e1287c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cu126\n",
      "CUDA available: True\n",
      "CUDA version: 12.6\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "To make the code device agnostic, the code below (from [PyTorch documentation](https://pytorch.org/docs/stable/notes/cuda.html#cuda-semantics)) checks if CUDA is available and sets the device accordingly. If CUDA is not available, it defaults to CPU. This way, you can run the same code on both CPU and GPU without any changes.",
   "id": "4cc117f363c70de1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Do not run this code here\n",
    "\n",
    "import argparse\n",
    "# import torch\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch Example')\n",
    "parser.add_argument('--disable-cuda', action='store_true',\n",
    "                    help='Disable CUDA')\n",
    "args = parser.parse_args()\n",
    "args.device = None\n",
    "if not args.disable_cuda and torch.cuda.is_available():\n",
    "    args.device = torch.device('cuda')\n",
    "else:\n",
    "    args.device = torch.device('cpu')\n",
    "\n",
    "# Example usage (not in the original code)\n",
    "#x = torch.empty((8, 42), device=args.device)\n",
    "# net = Network().to(device=args.device)"
   ],
   "id": "b24f5d97065bd71a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "A simpler implementation for smaller projects:",
   "id": "c991f586ecdeccf2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T15:54:44.676224Z",
     "start_time": "2025-04-18T15:54:44.672741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set device type\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ],
   "id": "aa6fad26e6513152",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's create a tensor and check its device:",
   "id": "7ad3771682d0ab3b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T15:54:45.716209Z",
     "start_time": "2025-04-18T15:54:45.712604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor = torch.tensor([1, 2, 3])\n",
    "print(tensor, tensor.device)"
   ],
   "id": "c34eec8083fcb32f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's now move the tensor to the GPU:",
   "id": "cea78b61c02e8a5b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T15:54:47.540065Z",
     "start_time": "2025-04-18T15:54:47.535529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor = tensor.to(device)\n",
    "print(tensor, tensor.device)"
   ],
   "id": "2acbb588e3e3d876",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3], device='cuda:0') cuda:0\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For some computations, for instance when using Numpy, we might need to move the tensor back to CPU. The `.cpu()` will copy the tensor to the CPU memory.",
   "id": "fe9d6ccd9973b56e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T15:55:02.374614Z",
     "start_time": "2025-04-18T15:55:02.371550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor_to_cpu = tensor.cpu().numpy()\n",
    "print(tensor_to_cpu, tensor_to_cpu.device)"
   ],
   "id": "90089de3e2d772d1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3] cpu\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The original tensor is still on the GPU, and we can check its device:",
   "id": "336d92c6a100223f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T15:55:03.835849Z",
     "start_time": "2025-04-18T15:55:03.832967Z"
    }
   },
   "cell_type": "code",
   "source": "print(tensor.device)",
   "id": "b995af6691507475",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's now do some tensor operations.",
   "id": "556fa7da7df50362"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T15:59:05.043880Z",
     "start_time": "2025-04-18T15:59:05.038495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "A = torch.rand(7, 7)\n",
    "A"
   ],
   "id": "673e727b7c614100",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9989, 0.2149, 0.0426, 0.9434, 0.8821, 0.6689, 0.2994],\n",
       "        [0.7143, 0.1341, 0.0160, 0.4524, 0.2977, 0.6134, 0.6843],\n",
       "        [0.4712, 0.2895, 0.7856, 0.2600, 0.8902, 0.4731, 0.6097],\n",
       "        [0.7839, 0.3622, 0.5973, 0.9278, 0.0310, 0.1695, 0.0028],\n",
       "        [0.4553, 0.1025, 0.3298, 0.8413, 0.5296, 0.4962, 0.9753],\n",
       "        [0.4377, 0.5322, 0.4453, 0.0715, 0.5955, 0.7760, 0.5759],\n",
       "        [0.4143, 0.2822, 0.3901, 0.3967, 0.6536, 0.2884, 0.9868]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T15:59:26.150387Z",
     "start_time": "2025-04-18T15:59:26.146445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "B = torch.rand(1, 7)\n",
    "B"
   ],
   "id": "e225a755e4ac7d9e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2236, 0.8643, 0.2792, 0.3037, 0.4342, 0.8267, 0.0259]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T15:59:46.560556Z",
     "start_time": "2025-04-18T15:59:46.556822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "C = torch.matmul(A, B.T)\n",
    "C"
   ],
   "id": "e6af448d1a815449",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6511],\n",
       "        [1.0715],\n",
       "        [1.4472],\n",
       "        [1.0905],\n",
       "        [1.2033],\n",
       "        [1.6189],\n",
       "        [1.1136]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T16:00:35.078576Z",
     "start_time": "2025-04-18T16:00:35.071589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "RANDOM_SEED = 0\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "A = torch.rand(7, 7)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "B = torch.rand(1, 7)\n",
    "\n",
    "C = torch.matmul(A, B.T)\n",
    "C"
   ],
   "id": "69d3b326a04e2bb2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5985],\n",
       "        [1.1173],\n",
       "        [1.2741],\n",
       "        [1.6838],\n",
       "        [0.8279],\n",
       "        [1.0347],\n",
       "        [1.2498]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T16:09:54.403648Z",
     "start_time": "2025-04-18T16:09:54.397443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CUDA_SEED = 1234\n",
    "torch.cuda.manual_seed(CUDA_SEED)\n",
    "D = torch.rand(2, 3).to(device)\n",
    "torch.cuda.manual_seed(CUDA_SEED)\n",
    "E = torch.rand(2, 3).to(device)\n",
    "F = torch.matmul(D, E.T).cpu()\n",
    "F"
   ],
   "id": "e4847a76ada48397",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4410, 0.3345],\n",
       "        [0.7856, 0.5843]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T16:09:55.199661Z",
     "start_time": "2025-04-18T16:09:55.194936Z"
    }
   },
   "cell_type": "code",
   "source": "torch.min(F), torch.max(F)",
   "id": "469553256d7ef11f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.3345), tensor(0.7856))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T16:09:55.919409Z",
     "start_time": "2025-04-18T16:09:55.915567Z"
    }
   },
   "cell_type": "code",
   "source": "torch.argmin(F), torch.argmax(F)",
   "id": "f75e4a0688bcc737",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1), tensor(2))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T16:15:14.743818Z",
     "start_time": "2025-04-18T16:15:14.739261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(7)\n",
    "G = torch.rand(1, 1, 1, 10)\n",
    "print(G)\n",
    "print(G.shape)"
   ],
   "id": "7d3be33178069103",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297,\n",
      "           0.3653, 0.8513]]]])\n",
      "torch.Size([1, 1, 1, 10])\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T16:15:39.667129Z",
     "start_time": "2025-04-18T16:15:39.664102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "G_squeeze = G.squeeze()\n",
    "print(G_squeeze)\n",
    "print(G_squeeze.shape)"
   ],
   "id": "139108395cb1c852",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297, 0.3653,\n",
      "        0.8513])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "execution_count": 63
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
